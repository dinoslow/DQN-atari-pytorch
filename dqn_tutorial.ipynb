{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"dqn_tutorial.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMSFPZ+5YMJIxa08l2rP+yE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cl30FhZS-Ir8"},"source":["# Deep Q Network Tutorial"]},{"cell_type":"markdown","metadata":{"id":"NuUUk1ttKXAQ"},"source":["## 1. Environment Preparation\n","### 1.1 Mount drive and set project path.\n","Mount the drive to let your program save/load the file in your space."]},{"cell_type":"code","metadata":{"id":"jK0QCNk9v4W8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624618518347,"user_tz":-480,"elapsed":478,"user":{"displayName":"陳文正","photoUrl":"","userId":"11767519788765263665"}},"outputId":"3df506eb-1ab7-4f04-be8e-f5145e7e0ea4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","project_root = '/content/drive/My Drive/DQN_tutorial/'\n","sys.path.append(project_root)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7HN4h_eeKhq6"},"source":["### 1.2 Download Atari ROM."]},{"cell_type":"code","metadata":{"id":"2J_47p11hM7y"},"source":["! wget http://www.atarimania.com/roms/Roms.rar\n","! mkdir /content/ROM/\n","! unrar e /content/Roms.rar /content/ROM/\n","! python -m atari_py.import_roms /content/ROM/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QHo6IpBN92O7"},"source":["## 2. Pong Game and Wrapper\n","### 2.1 Test the pong environment."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"g_SMe9nq91OI","executionInfo":{"status":"ok","timestamp":1624618545008,"user_tz":-480,"elapsed":1230,"user":{"displayName":"陳文正","photoUrl":"","userId":"11767519788765263665"}},"outputId":"faf65742-3544-4022-d256-8baf9304e647"},"source":["import gym\n","import matplotlib.pyplot as plt\n","\n","env_name = \"PongNoFrameskip-v4\"\n","env = gym.make(env_name)\n","\n","print(\"environment:\", env_name)\n","print(\"action space:\", env.action_space.n)\n","print(\"action:\", env.unwrapped.get_action_meanings())\n","print(\"observation space:\", env.observation_space.shape)\n","\n","state = env.reset()\n","action = env.action_space.sample()\n","state_next, reward, done, info = env.step(action)\n","plt.figure()\n","plt.imshow(state_next)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["environment: PongNoFrameskip-v4\n","action space: 6\n","action: ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n","observation space: (210, 160, 3)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fa23fac10d0>"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"y3S0ZQ_4AamT"},"source":["### 2.2 Environment wrapper.\n","The original pong game have high frame rate and resolution. We can preprocess the state to help the model learn faster and run efficiently.\n","\n","**Image Preprocessing**\n","- Resize the image to 84x84\n","- Transform the image to grayscale and float type.\n","- Binarization.\n","\n","**Stack Frames**<br>\n","- For each k continuous frames, we stack the processed images to construct the new state. The selected action will process k times to the environment."]},{"cell_type":"code","metadata":{"id":"6N8dWp49AUZC"},"source":["import numpy as np\n","from PIL import Image\n","\n","class PongEnvWrapper(gym.Wrapper):\n","    def __init__(self, env, k, img_size=(84,84)):\n","        gym.Wrapper.__init__(self, env)\n","        self.k = k\n","        self.img_size = img_size\n","        obs_shape = env.observation_space.shape\n","        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(k, img_size[0], img_size[1]), dtype=np.float32)\n","\n","    def _preprocess(self, state, th=0.4):\n","        state = np.array(Image.fromarray(state).resize(self.img_size,Image.BILINEAR))\n","        state = state.astype(np.float).mean(2) / 255.\n","        state[state > th] = 1.0\n","        state[state <=th] = 0.0\n","        return state\n","\n","    def reset(self):\n","        state = self.env.reset()\n","        state = self._preprocess(state)\n","        state = state[np.newaxis, ...].repeat(self.k, axis=0)\n","        return state\n","\n","    def step(self, action):\n","        state_next = []\n","        info = []\n","        reward = 0\n","        done = False\n","        for i in range(self.k):\n","            if not done:\n","                state_next_f, reward_f, done_f, info_f = self.env.step(action)\n","                state_next_f = self._preprocess(state_next_f)\n","                reward += reward_f\n","                done = done_f\n","                info.append(info_f)\n","            state_next.append(state_next_f[np.newaxis, ...])\n","        state_next = np.concatenate(state_next, 0)\n","\n","        return state_next, reward, done, info"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"id":"HPIdul6SAqg4","executionInfo":{"status":"ok","timestamp":1624618545549,"user_tz":-480,"elapsed":546,"user":{"displayName":"陳文正","photoUrl":"","userId":"11767519788765263665"}},"outputId":"cd14a1a7-a3a6-4974-fb7e-e5edd37ff7e3"},"source":["# Test Code\n","env_pong = PongEnvWrapper(env, k=4, img_size=(84,84))\n","print(\"observation space:\", env_pong.observation_space.shape)\n","\n","state = env_pong.reset()\n","action = env_pong.action_space.sample()\n","state_next, reward, done, info = env_pong.step(action)\n","print(state_next.shape)\n","plt.imshow(state_next[0], cmap=\"gray\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["observation space: (4, 84, 84)\n","(4, 84, 84)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fa23f5ddfd0>"]},"metadata":{"tags":[]},"execution_count":6},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"C8PmVn3yCeOK"},"source":["## 3. Reinforcement Learning\n","### 3.1 Convolutional Neural Network"]},{"cell_type":"code","metadata":{"id":"sHItigfeFp1p"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","class QNet(nn.Module):\n","    def __init__(self, input_shape, n_actions):\n","        super(QNet, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n","            nn.ReLU(),\n","        )\n","\n","        conv_out_size = self._get_conv_out(input_shape)\n","\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(conv_out_size, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, n_actions),\n","        )\n","    \n","    def _get_conv_out(self, shape):\n","        o = self.conv(torch.zeros(1, *shape))\n","        return int(np.prod(o.size()))\n","\n","    def forward(self, x):\n","        conv_out = self.conv(x)\n","        out = self.fc(conv_out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I6FmitVZFyOk"},"source":["### 3.2 DQN Algorithm\n","- TD-Error in original DQN.<br> \n","$L_{DQN}(\\theta)=\\mathbb{E}_{(s,a,r,s')\\sim U(D)}[(r+\\gamma\\max_{a'}Q(s',a';\\theta^{-})-Q(s,a;\\theta))^2]$<br><br>\n","- In Double DQN, utilize the max id of evaluation network to prevent the overestimation of Q-value.<br>\n","$L_{DDQN}(\\theta)=\\mathbb{E}_{(s,a,r,s')\\sim U(D)}[(r+\\gamma Q(s',{\\arg\\max}_{a'}{Q(s',a';\\theta)};\\theta^{-})-Q(s,a;\\theta))^2]$"]},{"cell_type":"code","metadata":{"id":"mZpRBeuXCol6"},"source":["class DeepQNetwork():\n","    def __init__(\n","        self,\n","        n_actions,\n","        input_shape,\n","        qnet,\n","        device,\n","        learning_rate = 2e-4,\n","        reward_decay = 0.99,\n","        replace_target_iter = 1000,\n","        memory_size = 10000,\n","        batch_size = 32,\n","    ):\n","        # initialize parameters\n","        self.n_actions = n_actions\n","        self.input_shape = input_shape\n","        self.lr = learning_rate\n","        self.gamma = reward_decay\n","        self.replace_target_iter = replace_target_iter\n","        self.memory_size = memory_size\n","        self.batch_size = batch_size\n","        self.device = device\n","        self.learn_step_counter = 0\n","        self.init_memory()\n","\n","        # Network\n","        self.qnet_eval = qnet(self.input_shape, self.n_actions).to(self.device)\n","        self.qnet_target = qnet(self.input_shape, self.n_actions).to(self.device)\n","        self.qnet_target.eval()\n","        self.optimizer = optim.RMSprop(self.qnet_eval.parameters(), lr=self.lr)\n","\n","    def choose_action(self, state, epsilon=0):\n","        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n","        actions_value = self.qnet_eval.forward(state)\n","        if np.random.uniform() > epsilon:   # greedy\n","            action = torch.max(actions_value, 1)[1].data.cpu().numpy()[0]\n","        else:   # random\n","            action = np.random.randint(0, self.n_actions)\n","        return action\n","\n","    def learn(self):\n","        # check to replace target parameters\n","        if self.learn_step_counter % self.replace_target_iter == 0:\n","            self.qnet_target.load_state_dict(self.qnet_eval.state_dict())\n","\n","        # sample batch memory from all memory\n","        if self.memory_counter > self.memory_size:\n","            sample_index = np.random.choice(self.memory_size, size=self.batch_size)\n","        else:\n","            sample_index = np.random.choice(self.memory_counter, size=self.batch_size)\n","\n","        b_s = torch.FloatTensor(self.memory[\"s\"][sample_index]).to(self.device)\n","        b_a = torch.LongTensor(self.memory[\"a\"][sample_index]).to(self.device)\n","        b_r = torch.FloatTensor(self.memory[\"r\"][sample_index]).to(self.device)\n","        b_s_ = torch.FloatTensor(self.memory[\"s_\"][sample_index]).to(self.device)\n","        b_d = torch.FloatTensor(self.memory[\"done\"][sample_index]).to(self.device)\n","\n","        q_curr_eval = self.qnet_eval(b_s).gather(1, b_a)\n","        q_next_target = self.qnet_target(b_s_).detach()\n","\n","        #next_state_values = q_next_target.max(1)[0].view(-1, 1)   # DQN\n","        q_next_eval = self.qnet_eval(b_s_).detach()\n","        next_state_values = q_next_target.gather(1, q_next_eval.max(1)[1].unsqueeze(1))   # DDQN\n","\n","        q_curr_recur = b_r + (1-b_d) * self.gamma * next_state_values\n","        self.loss = F.smooth_l1_loss(q_curr_eval, q_curr_recur)\n","\n","        self.optimizer.zero_grad()\n","        self.loss.backward()\n","        self.optimizer.step()\n","        self.learn_step_counter += 1\n","        return self.loss.detach().cpu().numpy()\n","\n","    def init_memory(self):\n","        self.memory = {\n","            \"s\": np.zeros((self.memory_size, *self.input_shape)),\n","            \"a\": np.zeros((self.memory_size, 1)),\n","            \"r\": np.zeros((self.memory_size, 1)),\n","            \"s_\": np.zeros((self.memory_size, *self.input_shape)),\n","            \"done\": np.zeros((self.memory_size, 1)),\n","        }\n","\n","    def store_transition(self, s, a, r, s_, d):\n","        if not hasattr(self, 'memory_counter'):\n","            self.memory_counter = 0\n","        if self.memory_counter <= self.memory_size:\n","            index = self.memory_counter % self.memory_size\n","        else:\n","            index = np.random.randint(self.memory_size)\n","        self.memory[\"s\"][index] = s\n","        self.memory[\"a\"][index] = np.array(a).reshape(-1,1)\n","        self.memory[\"r\"][index] = np.array(r).reshape(-1,1)\n","        self.memory[\"s_\"][index] = s_\n","        self.memory[\"done\"][index] = np.array(d).reshape(-1,1)\n","        self.memory_counter += 1\n","    \n","    def save_load_model(self, op, path=\"save\", fname=\"qnet.pt\"):\n","        import os\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","        file_path = os.path.join(path, fname)\n","        if op == \"save\":\n","            torch.save(self.qnet_eval.state_dict(), file_path)\n","        elif op == \"load\":\n","            self.qnet_eval.load_state_dict(torch.load(file_path, map_location=self.device))\n","            self.qnet_target.load_state_dict(torch.load(file_path, map_location=self.device))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZeHuwGZSFa7c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624618563191,"user_tz":-480,"elapsed":13187,"user":{"displayName":"陳文正","photoUrl":"","userId":"11767519788765263665"}},"outputId":"8fd27715-418a-410a-a092-345712763e64"},"source":["stack_frames = 4\n","img_size = (84,84)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","agent = DeepQNetwork(\n","        n_actions = env.action_space.n,\n","        input_shape = [stack_frames, *img_size],\n","        qnet = QNet,\n","        device = device,\n","        learning_rate = 2e-4, \n","        reward_decay = 0.99,\n","        replace_target_iter = 1000, \n","        memory_size = 10000,\n","        batch_size = 32,)\n","\n","print(agent.qnet_eval)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["QNet(\n","  (conv): Sequential(\n","    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n","    (1): ReLU()\n","    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n","    (3): ReLU()\n","    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (5): ReLU()\n","  )\n","  (fc): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=3136, out_features=512, bias=True)\n","    (2): ReLU()\n","    (3): Linear(in_features=512, out_features=6, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TlO1ozgFKsjC"},"source":["## 4. Training and testing process.\n","### 4.1 Play the game."]},{"cell_type":"code","metadata":{"id":"6gC66Kh7LS87"},"source":["def play(env, agent, stack_frames, img_size):\n","    # Reset environment.\n","    state = env.reset()\n","    img_buffer = [Image.fromarray(state[0]*255)]\n","\n","    # Initialize information.\n","    step = 0\n","    total_reward = 0\n","\n","    # One episode.\n","    while True:\n","        # Select action.\n","        action = agent.choose_action(state, 0)\n","\n","        # Get next stacked state.\n","        state_next, reward, done, info = env.step(action)\n","        if step % 2 == 0:\n","            img_buffer.append(Image.fromarray(state_next[0]*255))\n","\n","        state = state_next.copy()\n","        step += 1\n","        total_reward += reward\n","        print('\\rStep: {:3d} | Reward: {:.3f} / {:.3f}'\\\n","            .format(step, reward, total_reward), end=\"\")\n","            \n","        if done or step>2000:\n","            print()\n","            break\n","\n","    return img_buffer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4h71uAIcFVpj"},"source":["import os\n","def save_gif(img_buffer, fname, gif_path=os.path.join(project_root, \"gif\")):\n","    if not os.path.exists(gif_path):\n","        os.makedirs(gif_path)\n","    img_buffer[0].save(os.path.join(gif_path, fname), save_all=True, append_images=img_buffer[1:], duration=1, loop=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwvsjrHMTyOh","executionInfo":{"status":"ok","timestamp":1624618567127,"user_tz":-480,"elapsed":3946,"user":{"displayName":"陳文正","photoUrl":"","userId":"11767519788765263665"}},"outputId":"be6c64a1-01fc-4fd7-c822-207ec2944236"},"source":["# Test Code\n","img_buffer = play(env_pong, agent, stack_frames, img_size)\n","save_gif(img_buffer, fname=\"test.gif\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Step: 764 | Reward: -1.000 / -21.000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zaeYbrDBScJq"},"source":["### 4.2 Epsilon greedy computation.\n","- Annealing of $\\epsilon$<br>\n","$\\epsilon = \\epsilon_{min} + (\\epsilon_{max}-\\epsilon_{min})*\\exp({steps}/{\\epsilon_{decay}})$"]},{"cell_type":"code","metadata":{"id":"Z4CLYqqOSiHH"},"source":["def epsilon_compute(frame_id, epsilon_max=1, epsilon_min=0.05, epsilon_decay=100000):\n","    return epsilon_min + (epsilon_max - epsilon_min) * np.exp(-frame_id / epsilon_decay)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"tkS_5piBUU98","executionInfo":{"status":"ok","timestamp":1624618567128,"user_tz":-480,"elapsed":6,"user":{"displayName":"陳文正","photoUrl":"","userId":"11767519788765263665"}},"outputId":"e82bd2d4-b84f-4fa2-dad7-a7aa5e0b738b"},"source":["# Test Code\n","frame_ids = np.array(range(400000))\n","epsilons = epsilon_compute(frame_ids)\n","plt.plot(epsilons)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7fa1ddca4b50>]"]},"metadata":{"tags":[]},"execution_count":14},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"XrD-BxWCK-pa"},"source":["### 4.3 Training steps."]},{"cell_type":"code","metadata":{"id":"hj3uuC2w0JEr"},"source":["def train(env, agent, stack_frames, img_size, save_path=\"save\", max_steps=1000000):\n","    total_step = 0\n","    episode = 0\n","    while True:\n","        # Reset environment.\n","        state = env.reset()\n","\n","        # Initialize information.\n","        step = 0\n","        total_reward = 0\n","        loss = 0\n","\n","        # One episode.\n","        while True:\n","            # Select action.\n","            epsilon = epsilon_compute(total_step)\n","            action = agent.choose_action(state, epsilon)\n","\n","            # Get next stacked state.\n","            state_next, reward, done, info = env.step(action)\n","\n","            # Store transition and learn.\n","            agent.store_transition(state, action, reward, state_next, done)\n","            if total_step > 4*agent.batch_size:\n","                loss = agent.learn()\n","\n","            state = state_next.copy()\n","            step += 1\n","            total_step += 1\n","            total_reward += reward\n","\n","            if total_step % 100 == 0 or done:\n","                print('\\rEpisode: {:3d} | Step: {:3d} / {:3d} | Reward: {:.3f} / {:.3f} | Loss: {:.3f} | Epsilon: {:.3f}'\\\n","                    .format(episode, step, total_step, reward, total_reward, loss, epsilon), end=\"\")\n","            \n","            if total_step % 10000 == 0:\n","                print(\"\\nSave Model ...\")\n","                agent.save_load_model(op=\"save\", path=save_path, fname=\"qnet.pt\")\n","                print(\"Generate GIF ...\")\n","                img_buffer = play(env, agent, stack_frames, img_size)\n","                save_gif(img_buffer, \"train_\" + str(total_step).zfill(6) + \".gif\")\n","                print(\"Done !!\")\n","\n","            if done or step>2000:\n","                episode += 1\n","                print()\n","                break\n","        \n","        if total_step > max_steps:\n","            break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mHki_ukzyEpF","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1624621969607,"user_tz":-480,"elapsed":3401700,"user":{"displayName":"陳文正","photoUrl":"","userId":"11767519788765263665"}},"outputId":"bb3544da-a237-4d1f-983f-dbff61b22a85"},"source":["train(env_pong, agent, stack_frames, img_size, save_path=os.path.join(project_root, \"save\"), max_steps=400000)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Episode:   0 | Step: 872 / 872 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.992\n","Episode:   1 | Step: 764 / 1636 | Reward: -1.000 / -21.000 | Loss: 0.000 | Epsilon: 0.985\n","Episode:   2 | Step: 1153 / 2789 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.974\n","Episode:   3 | Step: 1106 / 3895 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.964\n","Episode:   4 | Step: 921 / 4816 | Reward: -1.000 / -19.000 | Loss: 0.000 | Epsilon: 0.955\n","Episode:   5 | Step: 854 / 5670 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.948\n","Episode:   6 | Step: 974 / 6644 | Reward: -1.000 / -19.000 | Loss: 0.000 | Epsilon: 0.939\n","Episode:   7 | Step: 965 / 7609 | Reward: -1.000 / -19.000 | Loss: 0.005 | Epsilon: 0.930\n","Episode:   8 | Step: 865 / 8474 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.923\n","Episode:   9 | Step: 842 / 9316 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.916\n","Episode:  10 | Step: 684 / 10000 | Reward: 0.000 / -16.000 | Loss: 0.001 | Epsilon: 0.910\n","Save Model ...\n","Generate GIF ...\n","Step: 1140 | Reward: -1.000 / -21.000\n","Done !!\n","Episode:  10 | Step: 685 / 10001 | Reward: 0.000 / -16.000 | Loss: 0.001 | Epsilon: 0.910\n","Episode:  11 | Step: 1057 / 11058 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.901\n","Episode:  12 | Step: 852 / 11910 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.893\n","Episode:  13 | Step: 1003 / 12913 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.885\n","Episode:  14 | Step: 1203 / 14116 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.875\n","Episode:  15 | Step: 1093 / 15209 | Reward: -1.000 / -20.000 | Loss: 0.007 | Epsilon: 0.866\n","Episode:  16 | Step: 990 / 16199 | Reward: -1.000 / -20.000 | Loss: 0.002 | Epsilon: 0.858\n","Episode:  17 | Step: 968 / 17167 | Reward: -1.000 / -20.000 | Loss: 0.005 | Epsilon: 0.850\n","Episode:  18 | Step: 1057 / 18224 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.842\n","Episode:  19 | Step: 1252 / 19476 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.832\n","Episode:  20 | Step: 524 / 20000 | Reward: 0.000 / -11.000 | Loss: 0.001 | Epsilon: 0.828\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -10.000\n","Done !!\n","Episode:  20 | Step: 787 / 20263 | Reward: -1.000 / -14.000 | Loss: 0.001 | Epsilon: 0.826\n","Episode:  21 | Step: 988 / 21251 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.818\n","Episode:  22 | Step: 933 / 22184 | Reward: -1.000 / -21.000 | Loss: 0.002 | Epsilon: 0.811\n","Episode:  23 | Step: 1154 / 23338 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.802\n","Episode:  24 | Step: 901 / 24239 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.796\n","Episode:  25 | Step: 990 / 25229 | Reward: -1.000 / -21.000 | Loss: 0.003 | Epsilon: 0.788\n","Episode:  26 | Step: 1127 / 26356 | Reward: -1.000 / -18.000 | Loss: 0.004 | Epsilon: 0.780\n","Episode:  27 | Step: 1040 / 27396 | Reward: -1.000 / -20.000 | Loss: 0.000 | Epsilon: 0.772\n","Episode:  28 | Step: 1043 / 28439 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.765\n","Episode:  29 | Step: 954 / 29393 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.758\n","Episode:  30 | Step: 607 / 30000 | Reward: 0.000 / -10.000 | Loss: 0.001 | Epsilon: 0.754\n","Save Model ...\n","Generate GIF ...\n","Step: 1599 | Reward: -1.000 / -19.000\n","Done !!\n","Episode:  30 | Step: 608 / 30001 | Reward: 0.000 / -10.000 | Loss: 0.000 | Epsilon: 0.754\n","Episode:  31 | Step: 1008 / 31009 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.747\n","Episode:  32 | Step: 1036 / 32045 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.740\n","Episode:  33 | Step: 1169 / 33214 | Reward: -1.000 / -20.000 | Loss: 0.002 | Epsilon: 0.732\n","Episode:  34 | Step: 1242 / 34456 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.723\n","Episode:  35 | Step: 1037 / 35493 | Reward: -1.000 / -20.000 | Loss: 0.002 | Epsilon: 0.716\n","Episode:  36 | Step: 1004 / 36497 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.710\n","Episode:  37 | Step: 1273 / 37770 | Reward: -1.000 / -19.000 | Loss: 0.000 | Epsilon: 0.701\n","Episode:  38 | Step: 1013 / 38783 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.695\n","Episode:  39 | Step: 1066 / 39849 | Reward: -1.000 / -19.000 | Loss: 0.007 | Epsilon: 0.688\n","Episode:  40 | Step: 151 / 40000 | Reward: 0.000 / -1.000 | Loss: 0.001 | Epsilon: 0.687\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -12.000\n","Done !!\n","Episode:  40 | Step: 461 / 40310 | Reward: -1.000 / -6.000 | Loss: 0.001 | Epsilon: 0.685\n","Episode:  41 | Step: 1080 / 41390 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.678\n","Episode:  42 | Step: 1287 / 42677 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.670\n","Episode:  43 | Step: 1325 / 44002 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.662\n","Episode:  44 | Step: 1521 / 45523 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.653\n","Episode:  45 | Step: 1013 / 46536 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.647\n","Episode:  46 | Step: 1168 / 47704 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.640\n","Episode:  47 | Step: 1181 / 48885 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.633\n","Episode:  48 | Step: 1115 / 50000 | Reward: 0.000 / -16.000 | Loss: 0.001 | Epsilon: 0.626\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -10.000\n","Done !!\n","Episode:  48 | Step: 1363 / 50248 | Reward: -1.000 / -22.000 | Loss: 0.001 | Epsilon: 0.625\n","Episode:  49 | Step: 1329 / 51577 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.617\n","Episode:  50 | Step: 1364 / 52941 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.610\n","Episode:  51 | Step: 1412 / 54353 | Reward: -1.000 / -16.000 | Loss: 0.002 | Epsilon: 0.602\n","Episode:  52 | Step: 1416 / 55769 | Reward: -1.000 / -19.000 | Loss: 0.002 | Epsilon: 0.594\n","Episode:  53 | Step: 1106 / 56875 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.588\n","Episode:  54 | Step: 1113 / 57988 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.582\n","Episode:  55 | Step: 1294 / 59282 | Reward: -1.000 / -20.000 | Loss: 0.003 | Epsilon: 0.575\n","Episode:  56 | Step: 718 / 60000 | Reward: 0.000 / -12.000 | Loss: 0.001 | Epsilon: 0.571\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -8.000\n","Done !!\n","Episode:  56 | Step: 1190 / 60472 | Reward: -1.000 / -21.000 | Loss: 0.005 | Epsilon: 0.569\n","Episode:  57 | Step: 1347 / 61819 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.562\n","Episode:  58 | Step: 1087 / 62906 | Reward: -1.000 / -20.000 | Loss: 0.000 | Epsilon: 0.556\n","Episode:  59 | Step: 1052 / 63958 | Reward: -1.000 / -20.000 | Loss: 0.000 | Epsilon: 0.551\n","Episode:  60 | Step: 1446 / 65404 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.544\n","Episode:  61 | Step: 1446 / 66850 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.537\n","Episode:  62 | Step: 1508 / 68358 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.530\n","Episode:  63 | Step: 1432 / 69790 | Reward: -1.000 / -19.000 | Loss: 0.000 | Epsilon: 0.523\n","Episode:  64 | Step: 210 / 70000 | Reward: 0.000 / -3.000 | Loss: 0.001 | Epsilon: 0.522\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 1.000 / -6.000\n","Done !!\n","Episode:  64 | Step: 591 / 70381 | Reward: -1.000 / -9.000 | Loss: 0.001 | Epsilon: 0.520\n","Episode:  65 | Step: 1338 / 71719 | Reward: -1.000 / -16.000 | Loss: 0.001 | Epsilon: 0.514\n","Episode:  66 | Step: 1452 / 73171 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.507\n","Episode:  67 | Step: 1290 / 74461 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.501\n","Episode:  68 | Step: 1473 / 75934 | Reward: -1.000 / -19.000 | Loss: 0.002 | Epsilon: 0.495\n","Episode:  69 | Step: 1224 / 77158 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.489\n","Episode:  70 | Step: 1274 / 78432 | Reward: -1.000 / -19.000 | Loss: 0.000 | Epsilon: 0.484\n","Episode:  71 | Step: 1568 / 80000 | Reward: 0.000 / -16.000 | Loss: 0.001 | Epsilon: 0.477\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -12.000\n","Done !!\n","Episode:  71 | Step: 1799 / 80231 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.476\n","Episode:  72 | Step: 1278 / 81509 | Reward: -1.000 / -19.000 | Loss: 0.000 | Epsilon: 0.470\n","Episode:  73 | Step: 1254 / 82763 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.465\n","Episode:  74 | Step: 1654 / 84417 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.458\n","Episode:  75 | Step: 1319 / 85736 | Reward: -1.000 / -19.000 | Loss: 0.000 | Epsilon: 0.453\n","Episode:  76 | Step: 1428 / 87164 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.447\n","Episode:  77 | Step: 1537 / 88701 | Reward: -1.000 / -18.000 | Loss: 0.021 | Epsilon: 0.441\n","Episode:  78 | Step: 1299 / 90000 | Reward: 0.000 / -19.000 | Loss: 0.002 | Epsilon: 0.436\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -13.000\n","Done !!\n","Episode:  78 | Step: 1387 / 90088 | Reward: -1.000 / -22.000 | Loss: 0.008 | Epsilon: 0.436\n","Episode:  79 | Step: 1386 / 91474 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.431\n","Episode:  80 | Step: 1564 / 93038 | Reward: -1.000 / -16.000 | Loss: 0.000 | Epsilon: 0.425\n","Episode:  81 | Step: 1957 / 94995 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.417\n","Episode:  82 | Step: 1425 / 96420 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.412\n","Episode:  83 | Step: 1906 / 98326 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.405\n","Episode:  84 | Step: 1327 / 99653 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.401\n","Episode:  85 | Step: 347 / 100000 | Reward: 0.000 / -5.000 | Loss: 0.001 | Epsilon: 0.399\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / 0.000\n","Done !!\n","Episode:  85 | Step: 1163 / 100816 | Reward: -1.000 / -17.000 | Loss: 0.000 | Epsilon: 0.397\n","Episode:  86 | Step: 1502 / 102318 | Reward: -1.000 / -16.000 | Loss: 0.001 | Epsilon: 0.391\n","Episode:  87 | Step: 1593 / 103911 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.386\n","Episode:  88 | Step: 1736 / 105647 | Reward: -1.000 / -15.000 | Loss: 0.001 | Epsilon: 0.380\n","Episode:  89 | Step: 1580 / 107227 | Reward: -1.000 / -19.000 | Loss: 0.003 | Epsilon: 0.375\n","Episode:  90 | Step: 1591 / 108818 | Reward: -1.000 / -17.000 | Loss: 0.002 | Epsilon: 0.370\n","Episode:  91 | Step: 1182 / 110000 | Reward: 0.000 / -7.000 | Loss: 0.001 | Epsilon: 0.366\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -14.000\n","Done !!\n","Episode:  91 | Step: 1417 / 110235 | Reward: -1.000 / -10.000 | Loss: 0.002 | Epsilon: 0.365\n","Episode:  92 | Step: 1789 / 112024 | Reward: -1.000 / -15.000 | Loss: 0.001 | Epsilon: 0.360\n","Episode:  93 | Step: 1664 / 113688 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.355\n","Episode:  94 | Step: 1608 / 115296 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.350\n","Episode:  95 | Step: 1904 / 117200 | Reward: 0.000 / -12.000 | Loss: 0.002 | Epsilon: 0.344\n","Episode:  96 | Step: 1903 / 119200 | Reward: 0.000 / -14.000 | Loss: 0.001 | Epsilon: 0.338\n","Episode:  97 | Step: 702 / 120000 | Reward: 0.000 / -5.000 | Loss: 0.001 | Epsilon: 0.336\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -11.000\n","Done !!\n","Episode:  97 | Step: 1066 / 120364 | Reward: -1.000 / -8.000 | Loss: 0.001 | Epsilon: 0.335\n","Episode:  98 | Step: 1789 / 122153 | Reward: -1.000 / -16.000 | Loss: 0.001 | Epsilon: 0.330\n","Episode:  99 | Step: 1775 / 123928 | Reward: -1.000 / -16.000 | Loss: 0.000 | Epsilon: 0.325\n","Episode: 100 | Step: 1972 / 125900 | Reward: 0.000 / -11.000 | Loss: 0.001 | Epsilon: 0.320\n","Episode: 101 | Step: 1971 / 127900 | Reward: 0.000 / -10.000 | Loss: 0.001 | Epsilon: 0.314\n","Episode: 102 | Step: 1806 / 129736 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.310\n","Episode: 103 | Step: 264 / 130000 | Reward: 0.000 / -5.000 | Loss: 0.001 | Epsilon: 0.309\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -8.000\n","Done !!\n","Episode: 103 | Step: 666 / 130402 | Reward: -1.000 / -10.000 | Loss: 0.000 | Epsilon: 0.308\n","Episode: 104 | Step: 1998 / 132400 | Reward: 0.000 / -11.000 | Loss: 0.001 | Epsilon: 0.303\n","Episode: 105 | Step: 1934 / 134337 | Reward: -1.000 / -14.000 | Loss: 0.001 | Epsilon: 0.298\n","Episode: 106 | Step: 1963 / 136300 | Reward: 0.000 / -12.000 | Loss: 0.001 | Epsilon: 0.293\n","Episode: 107 | Step: 1962 / 138300 | Reward: 0.000 / -12.000 | Loss: 0.001 | Epsilon: 0.288\n","Episode: 108 | Step: 1661 / 140000 | Reward: 0.000 / -16.000 | Loss: 0.002 | Epsilon: 0.284\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -3.000\n","Done !!\n","Episode: 108 | Step: 1961 / 140300 | Reward: 0.000 / -19.000 | Loss: 0.001 | Epsilon: 0.284\n","Episode: 109 | Step: 1583 / 141923 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.280\n","Episode: 110 | Step: 1950 / 143873 | Reward: -1.000 / -16.000 | Loss: 0.001 | Epsilon: 0.275\n","Episode: 111 | Step: 1927 / 145800 | Reward: 0.000 / -7.000 | Loss: 0.002 | Epsilon: 0.271\n","Episode: 112 | Step: 1926 / 147800 | Reward: 0.000 / -5.000 | Loss: 0.001 | Epsilon: 0.267\n","Episode: 113 | Step: 1925 / 149800 | Reward: 0.000 / -6.000 | Loss: 0.001 | Epsilon: 0.262\n","Episode: 114 | Step: 124 / 150000 | Reward: 0.000 / 0.000 | Loss: 0.000 | Epsilon: 0.262\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -2.000\n","Done !!\n","Episode: 114 | Step: 1347 / 151223 | Reward: -1.000 / -10.000 | Loss: 0.001 | Epsilon: 0.259\n","Episode: 115 | Step: 1977 / 153200 | Reward: 0.000 / -16.000 | Loss: 0.002 | Epsilon: 0.255\n","Episode: 116 | Step: 1976 / 155200 | Reward: 0.000 / -15.000 | Loss: 0.002 | Epsilon: 0.251\n","Episode: 117 | Step: 1975 / 157200 | Reward: 0.000 / -12.000 | Loss: 0.002 | Epsilon: 0.247\n","Episode: 118 | Step: 1974 / 159200 | Reward: 0.000 / -5.000 | Loss: 0.001 | Epsilon: 0.243\n","Episode: 119 | Step: 773 / 160000 | Reward: 0.000 / -5.000 | Loss: 0.001 | Epsilon: 0.242\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / 2.000\n","Done !!\n","Episode: 119 | Step: 1973 / 161200 | Reward: 0.000 / -14.000 | Loss: 0.001 | Epsilon: 0.240\n","Episode: 120 | Step: 1972 / 163200 | Reward: 0.000 / -12.000 | Loss: 0.007 | Epsilon: 0.236\n","Episode: 121 | Step: 1971 / 165200 | Reward: 0.000 / -9.000 | Loss: 0.002 | Epsilon: 0.232\n","Episode: 122 | Step: 1970 / 167200 | Reward: 0.000 / -10.000 | Loss: 0.001 | Epsilon: 0.228\n","Episode: 123 | Step: 1969 / 169200 | Reward: 0.000 / -1.000 | Loss: 0.002 | Epsilon: 0.225\n","Episode: 124 | Step: 768 / 170000 | Reward: 0.000 / -3.000 | Loss: 0.001 | Epsilon: 0.224\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -7.000\n","Done !!\n","Episode: 124 | Step: 1912 / 171144 | Reward: -1.000 / -9.000 | Loss: 0.001 | Epsilon: 0.222\n","Episode: 125 | Step: 1956 / 173100 | Reward: 0.000 / -6.000 | Loss: 0.000 | Epsilon: 0.218\n","Episode: 126 | Step: 1777 / 174922 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.215\n","Episode: 127 | Step: 1978 / 176900 | Reward: 0.000 / -3.000 | Loss: 0.001 | Epsilon: 0.212\n","Episode: 128 | Step: 1977 / 178900 | Reward: 0.000 / -5.000 | Loss: 0.001 | Epsilon: 0.209\n","Episode: 129 | Step: 1076 / 180000 | Reward: 0.000 / -2.000 | Loss: 0.000 | Epsilon: 0.207\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / 1.000\n","Done !!\n","Episode: 129 | Step: 1976 / 180900 | Reward: 0.000 / -8.000 | Loss: 0.000 | Epsilon: 0.206\n","Episode: 130 | Step: 1975 / 182900 | Reward: 0.000 / -6.000 | Loss: 0.000 | Epsilon: 0.203\n","Episode: 131 | Step: 1974 / 184900 | Reward: 0.000 / -9.000 | Loss: 0.001 | Epsilon: 0.200\n","Episode: 132 | Step: 1973 / 186900 | Reward: 0.000 / -7.000 | Loss: 0.004 | Epsilon: 0.197\n","Episode: 133 | Step: 1972 / 188900 | Reward: 0.000 / -10.000 | Loss: 0.001 | Epsilon: 0.194\n","Episode: 134 | Step: 1071 / 190000 | Reward: 0.000 / -5.000 | Loss: 0.001 | Epsilon: 0.192\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -1.000\n","Done !!\n","Episode: 134 | Step: 1971 / 190900 | Reward: 0.000 / -10.000 | Loss: 0.000 | Epsilon: 0.191\n","Episode: 135 | Step: 1970 / 192900 | Reward: 0.000 / -12.000 | Loss: 0.001 | Epsilon: 0.188\n","Episode: 136 | Step: 1969 / 194900 | Reward: 0.000 / -6.000 | Loss: 0.001 | Epsilon: 0.185\n","Episode: 137 | Step: 1968 / 196900 | Reward: 0.000 / -4.000 | Loss: 0.000 | Epsilon: 0.183\n","Episode: 138 | Step: 1967 / 198900 | Reward: 0.000 / -6.000 | Loss: 0.001 | Epsilon: 0.180\n","Episode: 139 | Step: 1066 / 200000 | Reward: 0.000 / -3.000 | Loss: 0.000 | Epsilon: 0.179\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / 1.000\n","Done !!\n","Episode: 139 | Step: 1966 / 200900 | Reward: 0.000 / -3.000 | Loss: 0.001 | Epsilon: 0.177\n","Episode: 140 | Step: 1965 / 202900 | Reward: 0.000 / 1.000 | Loss: 0.000 | Epsilon: 0.175\n","Episode: 141 | Step: 1964 / 204900 | Reward: 0.000 / -7.000 | Loss: 0.001 | Epsilon: 0.172\n","Episode: 142 | Step: 1963 / 206900 | Reward: 0.000 / -1.000 | Loss: 0.000 | Epsilon: 0.170\n","Episode: 143 | Step: 1962 / 208900 | Reward: 0.000 / -3.000 | Loss: 0.001 | Epsilon: 0.168\n","Episode: 144 | Step: 1061 / 210000 | Reward: 0.000 / -8.000 | Loss: 0.001 | Epsilon: 0.166\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / 0.000\n","Done !!\n","Episode: 144 | Step: 1961 / 210900 | Reward: 0.000 / -13.000 | Loss: 0.001 | Epsilon: 0.165\n","Episode: 145 | Step: 1960 / 212900 | Reward: 0.000 / -10.000 | Loss: 0.000 | Epsilon: 0.163\n","Episode: 146 | Step: 1959 / 214900 | Reward: 0.000 / -4.000 | Loss: 0.002 | Epsilon: 0.161\n","Episode: 147 | Step: 1958 / 216900 | Reward: 0.000 / -3.000 | Loss: 0.001 | Epsilon: 0.159\n","Episode: 148 | Step: 1957 / 218900 | Reward: 0.000 / -5.000 | Loss: 0.001 | Epsilon: 0.156\n","Episode: 149 | Step: 1056 / 220000 | Reward: 0.000 / -5.000 | Loss: 0.000 | Epsilon: 0.155\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -1.000\n","Done !!\n","Episode: 149 | Step: 1956 / 220900 | Reward: 0.000 / -5.000 | Loss: 0.000 | Epsilon: 0.154\n","Episode: 150 | Step: 1955 / 222900 | Reward: 0.000 / 2.000 | Loss: 0.000 | Epsilon: 0.152\n","Episode: 151 | Step: 1954 / 224900 | Reward: 0.000 / -6.000 | Loss: 0.000 | Epsilon: 0.150\n","Episode: 152 | Step: 1953 / 226900 | Reward: 0.000 / -3.000 | Loss: 0.000 | Epsilon: 0.148\n","Episode: 153 | Step: 1952 / 228900 | Reward: 0.000 / -2.000 | Loss: 0.000 | Epsilon: 0.146\n","Episode: 154 | Step: 1051 / 230000 | Reward: 0.000 / -1.000 | Loss: 0.000 | Epsilon: 0.145\n","Save Model ...\n","Generate GIF ...\n","Step: 2001 | Reward: 0.000 / -1.000\n","Done !!\n","Episode: 154 | Step: 1951 / 230900 | Reward: 0.000 / -2.000 | Loss: 0.001 | Epsilon: 0.144\n","Episode: 155 | Step: 1350 / 232300 | Reward: 0.000 / 1.000 | Loss: 0.001 | Epsilon: 0.143"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-9b39f679e3eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_pong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"save\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-3c670aea645a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(env, agent, stack_frames, img_size, save_path, max_steps)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtotal_step\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-da71a865abc0>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mq_curr_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnet_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mq_next_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnet_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_s_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m#next_state_values = q_next_target.max(1)[0].view(-1, 1)   # DQN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-7cf8c9a6fefb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"Igf0N-DQLC_u"},"source":["### 4.4 Evaluate the trained model."]},{"cell_type":"code","metadata":{"id":"KTVutI83Iv4H"},"source":["agent.save_load_model(op=\"load\", path=os.path.join(project_root, \"save\"), fname=\"qnet.pt\")\n","img_buffer = play(env_pong, agent, stack_frames, img_size)\n","save_gif(img_buffer, \"eval.gif\")"],"execution_count":null,"outputs":[]}]}